机器学习第四章

### 1. 当训练集有百万的特征时，哪种线性回归算法会使用？


### 2. 当你的训练集特征中有很多不同量级的特征时，哪种线性回归算法会出现问题？怎么解决？


### 3. 在训练逻辑回归模型时，当梯度下降算法会困在局部最小中吗？


### 4. 是否所有的梯度下降算法在足够的运行时间都会产生相同的模型？


### 5. 假设你使用批量梯度下降，并每个周期绘制验证集的误差，如果你注意到验证集误差在持续上升，这时发生了什么？如何解决这个问题？


### 6. 使用小批量梯度下降时，在验证集误差上升时，是否应该立刻停止？


### 7. 在三种梯度下降算法中，哪种可以快速地到达最优解附近？哪个会实际的收敛？如何使其他的算法也收敛？


### 8. 假设你使用多项式回归，绘制学习曲线时，你发现在训练集和验证集误差有个很大的差距，发生了什么？有哪些处理办法？


### 9. 假设你使用Ridge回归，你发现验证集和训练集误差基本相同，而且都很高，模型是因为高的偏差还是高的方差？应该如何调整正则化参数？


### 10. Ridge回归，Lasso回归，ElasticNet回归的区别？


### 11. 如果你想把图片分类为室内或者室外、白天或者夜晚，你应该实现两种逻辑回归还是一种softmax回归分类器？

